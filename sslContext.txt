import pytest
from pyspark.sql import SparkSession
from pyspark.sql.functions import col
from unittest.mock import patch, MagicMock

@pytest.fixture(scope="session")
def spark():
    return SparkSession.builder.master("local").appName("TestSession").getOrCreate()

@pytest.fixture
def input_dataframes(spark):
    # Load input CSVs
    job_signoff_df = spark.read.options(header=True, delimiter=".").csv("tests/unit/inputfiles/job_signoff.csv")
    job_inst_df = spark.read.options(header=True, delimiter=".").csv("tests/unit/inputfiles/job_inst_cib_invoice.csv")
    fe_cib_invoice_raw_df = spark.read.options(header=True, delimiter=".").csv("tests/unit/inputfiles/fe_cib_invoice_raw.csv")
    hrchy_entity_inst_fe_df = spark.read.options(header=True, delimiter=".").csv("tests/unit/inputfiles/hrchy_entity_inst_fe.csv")

    return {
        "job_signoff_df": job_signoff_df,
        "job_inst_df": job_inst_df,
        "fe_cib_invoice_raw_df": fe_cib_invoice_raw_df,
        "hrchy_entity_inst_fe_df": hrchy_entity_inst_fe_df
    }

def test_dataframe_join(spark, input_dataframes):
    # Extract input DataFrames
    src_dataframe = input_dataframes["fe_cib_invoice_raw_df"]
    hie_dataframe_ccy_whr = input_dataframes["hrchy_entity_inst_fe_df"]

    # Perform join as in the original code
    df_joined_src_ccy = src_dataframe.alias('src').join(
        hie_dataframe_ccy_whr.alias('hie_ccy'),
        on=col('src.SUB_FUND_CCY') == col('hie_ccy.ENTITY_NM'),
        how="left"
    ).select(
        col('src.PROCESSING_MED'), col('src.TW04_INVOICE_SECTION'),
        col('hie_ccy.ENTITY_CD').alias('ccy_Ref_Hie_Cd')
    )

    # Assert output is not empty
    assert df_joined_src_ccy.count() > 0, "Join operation returned empty DataFrame"

    # Validate expected columns exist
    expected_columns = {'PROCESSING_MED', 'TW04_INVOICE_SECTION', 'ccy_Ref_Hie_Cd'}
    assert expected_columns.issubset(set(df_joined_src_ccy.columns)), "Missing expected columns"

def test_mock_join():
    with patch.object(SparkSession, 'read', return_value=MagicMock()) as mock_read:
        fe_cib_invoice_raw_df = mock_read.csv("tests/unit/inputfiles/fe_cib_invoice_raw.csv")

        with patch.object(fe_cib_invoice_raw_df, 'join', return_value=MagicMock()) as mock_join:
            result = fe_cib_invoice_raw_df.join(MagicMock(), on="SUB_FUND_CCY", how="left")
            assert mock_join.called, "Join was not executed"
